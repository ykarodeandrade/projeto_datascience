{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nome: Ykaro de Sousa Andrade"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tema do projeto \n",
    "## Produto: Marca multinacional PUMA.\n",
    "\n",
    "Tal escolha foi feita pois desde que o jogador de futebol Neymar Jr assumiu como o mais novo garoto propaganda da Puma, a marca come√ßou a ter um maior engajamento nas redes sociais. Por este motivo, analisar os dados obtidos ap√≥s tal repercuss√£o no twitter √© fator primordial para que haja um melhor entendimento da opini√£o dos clientes e assim aprimorar as pr√≥ximas campanhas de marketing da empresa por exemplo.\n",
    "\n",
    "\n",
    "Foi obtido uma base de dados com tweets postados pelos usu√°rios da rede social. A partir disso, classificou-se os tweets entre relevantes e irrelevantes. A partir disso **classificou-se como tweets relevantes todos aqueles que enalteciam a marca**, e em contra partida **classificou-se como tweets irrelevante todos aqueles que falavam mal da marca ou n√£o tinham rela√ß√£o direta com a Puma**.\n",
    "\n",
    "\n",
    "Dessarte, ao analisar os tweets, percebeu-se que os assuntos mais frequentemente relacionados a marca se tratavam de:\n",
    "\n",
    "‚Ä¢\tDesde que o Neymar foi contratado para ser garoto propaganda, a Puma come√ßou a fabricar produtos mais bonitos;\n",
    "\n",
    "‚Ä¢\t Devido a alguma pe√ßa do vestu√°rio da Puma que o Neymar foi visto usando, o p√∫blico tinha maior interesse em adiquirir o produto;\n",
    "\n",
    "‚Ä¢\t Observou-se muitos tweets relacionados √† marca onde a enquadrava como pertencente ao top3 marcas mundiais, tais como: Nike e Adidas;\n",
    "\n",
    "‚Ä¢   Internautas comentaram sobre o design das pe√ßas estarem mais bonitos;\n",
    "\n",
    "‚Ä¢\tTweets relacionados a satisfa√ß√£o dos f√£s desde que que Neymar se tornou patrocinado da Puma;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando bibliotecas\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display\n",
    "pd.options.display.max_rows = 13\n",
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\ykaro\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Documentos\\3 semestre\\Ci√™ncia dos Dados\\Projeto Classificador Naive Bayes\\projeto_datascience\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo fun√ß√£o de limpeza dos caracteres dos tweets e espa√ßando os emajis e palavras corretamente.\n",
    "\n",
    "def cleanup(text):\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;\\n)(*$#@''\"\"]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    text_subbed = emoji.get_emoji_regexp().split(text_subbed) #emoji\n",
    "    return ' '.join(text_subbed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'puma.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Irrelevante 0 / Relevante 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o neymar inovou a puma https://t.co/qtcuvd1svj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a @puma t√° deitando nas chuteiras do neymar, m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fico assim no da puma affss https://t.co/1ygyh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g_estrella__ puma t√° a√≠ , mas tr√™s listra t√° ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@0ketlyn_s eu acho que um puma ^^</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  \\\n",
       "0     o neymar inovou a puma https://t.co/qtcuvd1svj   \n",
       "1  a @puma t√° deitando nas chuteiras do neymar, m...   \n",
       "2  fico assim no da puma affss https://t.co/1ygyh...   \n",
       "3  @g_estrella__ puma t√° a√≠ , mas tr√™s listra t√° ...   \n",
       "4                  @0ketlyn_s eu acho que um puma ^^   \n",
       "\n",
       "   Irrelevante 0 / Relevante 1  \n",
       "0                            1  \n",
       "1                            1  \n",
       "2                            0  \n",
       "3                            1  \n",
       "4                            0  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Irrelevante 0 / Relevante 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@0chavex0 @ornate_puma vdd to resfriado</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üìΩ neymar e puma üëÄ‚ù§!!\\ntemos novidades vindo a√≠...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@brgmsch mas a puma nem patrocina a aston</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üìΩ puma neymar jr creativity  a inovadora chute...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a puma t√° a evoluir muito, quem me dera que o ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  \\\n",
       "0            @0chavex0 @ornate_puma vdd to resfriado   \n",
       "1  üìΩ neymar e puma üëÄ‚ù§!!\\ntemos novidades vindo a√≠...   \n",
       "2          @brgmsch mas a puma nem patrocina a aston   \n",
       "3  üìΩ puma neymar jr creativity  a inovadora chute...   \n",
       "4  a puma t√° a evoluir muito, quem me dera que o ...   \n",
       "\n",
       "   Irrelevante 0 / Relevante 1  \n",
       "0                            0  \n",
       "1                            1  \n",
       "2                            0  \n",
       "3                            1  \n",
       "4                            1  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O projeto consiste na an√°lise de tweets da marca esportiva Puma.**\n",
    "\n",
    "\n",
    "Foi definido como premissa que os tweets relevantes seriam todos aqueles que exaltavam a marca em seus coment√°rios, em contra partida os tweets irrelevantes seriam todos os outros, ou seja, os que n√£o tinham rela√ß√£o direta com a marca e/ou falavam mal da Puma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todos os tweets da base de dados :\n",
    "dados = pd.read_excel('puma.xlsx')\n",
    "#dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando apenas a planilha de Treinamento :\n",
    "t_treinamento = dados.loc[:, 'Treinamento']\n",
    "#t_treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processo de limpeza dos tweets de treinamento usando a fun√ß√£o que definimos como cleanup.\n",
    "lista_limpa = []\n",
    "for index, argumento in enumerate (t_treinamento):\n",
    "    #print(f'posi√ß√£o {index} tweeter: {argumento}')\n",
    "    limpa = cleanup(argumento.lower())\n",
    "    lista_limpa.append(limpa)\n",
    "    \n",
    "#print(lista_limpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Criando um novo data frame com os tweets de treinamentos limpos\n",
    "dados['Limpo'] = lista_limpa\n",
    "#dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando apenas os tweets relevantes e os adicionando em uma nova vari√°vel\n",
    "relevante = dados.loc[dados['Irrelevante 0 / Relevante 1'] == 1, 'Limpo']\n",
    "#relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1¬∞ for: Separar os tweets relevantes em palavras relevantes dando um split em cada tweet.\n",
    "p_relevantes = [] \n",
    "for c,conteudo in enumerate (relevante):\n",
    "    p_relevantes.append(conteudo.split())\n",
    "    \n",
    "#print(p_relevantes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Definindo todas as palvras revelantes em um conjunto\n",
    "todas_palavras_relevantes=[]\n",
    "for index, conteudo in enumerate(p_relevantes):\n",
    "    cont=0\n",
    "    while cont < len(p_relevantes[index]):\n",
    "        novo= conteudo[cont]\n",
    "        todas_palavras_relevantes.append(novo)\n",
    "        cont+=1\n",
    "#print(todas_palavras_relevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O total de Palavras relevantes √© 1730\n"
     ]
    }
   ],
   "source": [
    "# Informando o total de palavras dos tweets relevantes\n",
    "print(f' O total de Palavras relevantes √© {len(todas_palavras_relevantes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo uma nova limpeza, retirando todos os 'https', pois est√° str n√£o √© relevante para nossa an√°lise\n",
    "lista_de_links = []\n",
    "for index, conteudo in enumerate(todas_palavras_relevantes):\n",
    "    #print(f'{index}: {conteudo}')\n",
    "    cont = 0\n",
    "    while cont < len(todas_palavras_relevantes[index]):\n",
    "        #print(conteudo[cont])\n",
    "        if conteudo[cont:5] == 'https':\n",
    "            #print(f' palvra: {lista[index]} na posi√ß√£o {index}')\n",
    "            lista_de_links.append(todas_palavras_relevantes[index])\n",
    "        cont+=1\n",
    "\n",
    "lista_nova_r = []\n",
    "cont2 = 0\n",
    "while cont2 < len(todas_palavras_relevantes):\n",
    "    if todas_palavras_relevantes[cont2] not in lista_de_links:\n",
    "        lista_nova_r.append(todas_palavras_relevantes[cont2])\n",
    "    cont2+=1\n",
    "\n",
    "# Atualiza√ß√£o da vari√°vel todas_palavras_relevantes sem os https:\n",
    "\n",
    "todas_palavras_relevantes= lista_nova_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O total de Palavras relevantes sem a string \"htpps\" √© 1691\n"
     ]
    }
   ],
   "source": [
    "print(f' O total de Palavras relevantes sem a string \"htpps\" √© {len(todas_palavras_relevantes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Guardando as palavras como um pd.Series\n",
    "serie_relevante = pd.Series(todas_palavras_relevantes)\n",
    "\n",
    "# Frequencia absoluta de palavras relevantes\n",
    "tabela_relevante = serie_relevante.value_counts()\n",
    "#tabela_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Fazendo o mesmo para as palavras irrelevantes\"></div>\n",
    "\n",
    "# Fazendo o mesmo para as palavras irrelevantes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando apenas os tweets irrelevantes e os adicionando em uma nova vari√°vel\n",
    "irrelevante = dados.loc[dados['Irrelevante 0 / Relevante 1'] == 0, 'Limpo']\n",
    "#irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1¬∞ for: Separar os tweets irrelevantes em palavras irrelevantes dando um split em cada tweet.\n",
    "p_irrelevantes = []\n",
    "for index, conteudo in enumerate (irrelevante):\n",
    "    p_irrelevantes.append(conteudo.split())\n",
    "    \n",
    "# print(p_irrelevantes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definindo todas as palvras irrevelantes em um conjunto\n",
    "todas_palavras_irrelevantes=[]\n",
    "for index, conteudo in enumerate(p_irrelevantes):\n",
    "    cont=0\n",
    "    while cont < len(p_irrelevantes[index]):\n",
    "        novo= conteudo[cont]\n",
    "        todas_palavras_irrelevantes.append(novo)\n",
    "        cont+=1\n",
    "#print(todas_palavras_irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O total de Palavras irrelevantes √© 3115\n"
     ]
    }
   ],
   "source": [
    "# Informando o total de palavras dos tweets relevantes\n",
    "print(f' O total de Palavras irrelevantes √© {len(todas_palavras_irrelevantes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Aprimorando a limpeza dos Tweets\n",
    "# Fazendo limpeza de links iniciados com http. \n",
    "\n",
    "lista_de_links= []\n",
    "for index, conteudo in enumerate(todas_palavras_irrelevantes):\n",
    "    #print(f'{index}: {conteudo}')\n",
    "    cont = 0\n",
    "    while cont < len(todas_palavras_irrelevantes[index]):\n",
    "        #print(conteudo[cont])\n",
    "        if conteudo[cont:5] == 'https':\n",
    "            #print(f' palvra: {lista[index]} na posi√ß√£o {index}')\n",
    "            lista_de_links.append(todas_palavras_irrelevantes[index])\n",
    "        cont+=1\n",
    "\n",
    "lista_nova_irr = []\n",
    "cont2 = 0\n",
    "while cont2 < len(todas_palavras_irrelevantes):\n",
    "    if todas_palavras_irrelevantes[cont2] not in lista_de_links:\n",
    "        lista_nova_irr.append(todas_palavras_irrelevantes[cont2])\n",
    "    cont2+=1\n",
    "\n",
    "# Atualiza√ß√£o da vari√°vel todas_palavras_relevantes sem os https:\n",
    "\n",
    "todas_palavras_irrelevantes= lista_nova_irr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O total de Palavras irrelevantes sem os \"htpps\": 3067\n"
     ]
    }
   ],
   "source": [
    "print(f' O total de Palavras irrelevantes sem os \"htpps\": {len(todas_palavras_irrelevantes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardando as palavras irrelevantes como um pd.Series\n",
    "serie_irrelevante = pd.Series(todas_palavras_irrelevantes)\n",
    "\n",
    "# Frequencia absoluta de palavras relevantes\n",
    "tabela_irrelevante = serie_irrelevante.value_counts()\n",
    "#tabela_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas as palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O total de palavras com repeti√ß√£o √© 4758\n"
     ]
    }
   ],
   "source": [
    "# Total de palavras com repeti√ß√£o.\n",
    "total_de_palavras = todas_palavras_relevantes + todas_palavras_irrelevantes\n",
    "print(f'O total de palavras com repeti√ß√£o √© {len(total_de_palavras)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = pd.concat([serie_relevante, serie_irrelevante])\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_p_sem_r = x.value_counts().shape[0]\n",
    "#total_p_sem_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teorema de Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35540142917192097\n",
      "0.644598570828079\n",
      "4758\n"
     ]
    }
   ],
   "source": [
    "# Calculando as probabilidades \n",
    "\n",
    "Probabilidade_de_ser_relevante = len(todas_palavras_relevantes)/len(total_de_palavras)\n",
    "Probabilidade_de_ser_irrelevante = len(todas_palavras_irrelevantes)/len(total_de_palavras)\n",
    "print(Probabilidade_de_ser_relevante)\n",
    "print(Probabilidade_de_ser_irrelevante)\n",
    "print(len(total_de_palavras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.59\n",
       "1    0.41\n",
       "Name: Irrelevante 0 / Relevante 1, dtype: float64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planilha_teste = pd.read_excel('puma.xlsx', sheet_name = 'Teste')\n",
    "planilha_teste['Irrelevante 0 / Relevante 1'].value_counts(True)\n",
    "#planilha_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando apenas a planilha de Testes.\n",
    "t_teste = planilha_teste.loc[:, 'Teste']\n",
    "#t_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando os tweets de teste usando a fun√ß√£o que definimos como cleanup.\n",
    "lista2_limpa = []\n",
    "for index, argumento in enumerate (t_teste):\n",
    "    #print(f'posi√ß√£o {index} tweeter: {argumento}')\n",
    "    limpa = cleanup(argumento.lower())\n",
    "    lista2_limpa.append(limpa)\n",
    "    \n",
    "#print(lista2_limpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1¬∞ for: Separar os tweets relevantes em palavras relevantes dando um split\n",
    "lista_geral_teste= [] \n",
    "for c,conteudo in enumerate (lista2_limpa):\n",
    "    lista_geral_teste.append(conteudo.split())\n",
    "    \n",
    "#print(lista_geral_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teorema de Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"a-ingenuidade-naive-bayes\"></div>\n",
    "\n",
    "### A ingenuidade - Na√Øve Bayes\n",
    "\n",
    "Agora vamos a parte da ing√™nua do Na√Øve Bayes.\n",
    "Tal igenuidade consiste em assumir que as palavras s√£o independentes entre si e que sua ordem na frase n√£o importa. \n",
    "\n",
    "\n",
    "\n",
    "$\\quad P(tweet|R) = \n",
    "P( o |R)\\cdot P( neymar |R)\\cdot P( inovou |R)\\cdot P( a |R)\\cdot P( puma |R)$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Vamos denotar **Tweets Relevantes** simplesmente como $R$, para ficar melhor a visualiza√ß√£o para a aplica√ß√£o do Teorema de Bayes.\n",
    "\n",
    "Assim, a f√≥rmula completa fica:\n",
    "\n",
    "$P(R|tweet) = \\frac{P(o|R).P(neymar|R).P(inovou|R).P(a|R).P(puma|R).P(R)}{P(tweet)}$\n",
    "\n",
    "<br>\n",
    "\n",
    "Da mesma forma, denotando **Os Tweets irrelevantes** como $IRR$, a f√≥rmula completa fica:\n",
    "\n",
    "$P(IRR|tweet) = \\frac{P(o|IRR).P(neymar|IRR).P(inovou|IRR).P(a|IRR).P(puma|IRR).P(IRR)}{P(tweet)}$\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "Note que o denominador das duas probabilidade condicionais acima √© o mesmo, para fazer a classifica√ß√£o do tweet podemos cancelar o c√°lculo do denominador $P(tweet)$. \n",
    "\n",
    "Assim, a **Classifica√ß√£o da frase** se dar√° conforme abaixo:\n",
    "\n",
    "$\\quad \\Rightarrow$ Se $P(R|tweet) > P(IRR|tweet)$, ent√£o frase ser√° classificada como um *Tweet Relevante*.\n",
    "\n",
    "$\\quad \\Rightarrow$ Se $P(R|tweet) < P(IRR|tweet)$, ent√£o frase ser√° classificada como um *Tweet Irrelevante*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo classifica√ß√£o dos tweets da planilha teste\n",
    "\n",
    "lista_classificador = []\n",
    "\n",
    "laplace_relevante = Probabilidade_de_ser_relevante\n",
    "laplace_irrelevante = Probabilidade_de_ser_irrelevante\n",
    "\n",
    "\n",
    "for tweet in lista_geral_teste:\n",
    "    \n",
    "    for palavra in tweet:\n",
    "    \n",
    "        if palavra not in tabela_relevante and palavra not in tabela_irrelevante:\n",
    "            laplace_relevante *= (0 + 1) / (len(todas_palavras_relevantes) + total_p_sem_r)\n",
    "            laplace_irrelevante *= (0 + 1) / (len(todas_palavras_irrelevantes) + total_p_sem_r)\n",
    "\n",
    "\n",
    "        elif palavra not in tabela_irrelevante and palavra in tabela_relevante:\n",
    "            laplace_irrelevante *= (0 + 1) / (len(todas_palavras_irrelevantes) + total_p_sem_r)\n",
    "            laplace_relevante *= (tabela_relevante[palavra] + 1) / (len(todas_palavras_relevantes) + total_p_sem_r)\n",
    "\n",
    "        elif palavra not in tabela_relevante and palavra in tabela_irrelevante:\n",
    "            laplace_relevante *= (0 + 1) / (len(todas_palavras_relevantes) + total_p_sem_r)\n",
    "            laplace_irrelevante *= (tabela_irrelevante[palavra] + 1) / (len(todas_palavras_irrelevantes) + total_p_sem_r)\n",
    "\n",
    "\n",
    "\n",
    "        elif palavra in tabela_relevante and palavra in tabela_irrelevante:\n",
    "            laplace_relevante *= (tabela_relevante[palavra] + 1) / (len(todas_palavras_relevantes) + total_p_sem_r)\n",
    "            laplace_irrelevante *= (tabela_irrelevante[palavra] + 1) / (len(todas_palavras_irrelevantes) + total_p_sem_r)\n",
    "\n",
    "\n",
    "\n",
    "    if laplace_relevante > laplace_irrelevante:\n",
    "        lista_classificador.append(1)\n",
    "    else:\n",
    "        lista_classificador.append(0)\n",
    "    \n",
    "    laplace_relevante = Probabilidade_de_ser_relevante\n",
    "    laplace_irrelevante = Probabilidade_de_ser_irrelevante\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Irrelevante 0 / Relevante 1</th>\n",
       "      <th>Algoritimo Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@0chavex0 @ornate_puma vdd to resfriado</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üìΩ neymar e puma üëÄ‚ù§!!\\ntemos novidades vindo a√≠...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@brgmsch mas a puma nem patrocina a aston</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üìΩ puma neymar jr creativity  a inovadora chute...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a puma t√° a evoluir muito, quem me dera que o ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neymar de puma ü§§</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@anthrpocene puma √© a √∫nica m√∫sica deles que n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@slbdiogo_ warning: eu quero a puma este mano ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@srtonalves palmeiras tem dinheiro de vendas d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>agora fudeu o caralho todo mermo vao puma porra</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  \\\n",
       "0            @0chavex0 @ornate_puma vdd to resfriado   \n",
       "1  üìΩ neymar e puma üëÄ‚ù§!!\\ntemos novidades vindo a√≠...   \n",
       "2          @brgmsch mas a puma nem patrocina a aston   \n",
       "3  üìΩ puma neymar jr creativity  a inovadora chute...   \n",
       "4  a puma t√° a evoluir muito, quem me dera que o ...   \n",
       "5                                   neymar de puma ü§§   \n",
       "6  @anthrpocene puma √© a √∫nica m√∫sica deles que n...   \n",
       "7  @slbdiogo_ warning: eu quero a puma este mano ...   \n",
       "8  @srtonalves palmeiras tem dinheiro de vendas d...   \n",
       "9    agora fudeu o caralho todo mermo vao puma porra   \n",
       "\n",
       "   Irrelevante 0 / Relevante 1  Algoritimo Classificador  \n",
       "0                            0                         0  \n",
       "1                            1                         1  \n",
       "2                            0                         0  \n",
       "3                            1                         1  \n",
       "4                            1                         0  \n",
       "5                            1                         1  \n",
       "6                            0                         0  \n",
       "7                            0                         1  \n",
       "8                            0                         0  \n",
       "9                            0                         0  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planilha_teste[\"Algoritimo Classificador\"] = lista_classificador\n",
    "planilha_teste.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Algoritimo Classificador</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irrelevante 0 / Relevante 1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.085</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algoritimo Classificador         0      1\n",
       "Irrelevante 0 / Relevante 1              \n",
       "0                            0.330  0.260\n",
       "1                            0.085  0.325"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pd.crosstab(planilha_teste['Irrelevante 0 / Relevante 1'], planilha_teste['Algoritimo Classificador'], normalize=True)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performace do Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A performace do Classificador de tweets √© de 65.5%\n"
     ]
    }
   ],
   "source": [
    "y = m[0][0] + m[1][1]\n",
    "print(f'A performace do Classificador de tweets √© de {100*y}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acur√°cia do Classificador √© de 65.5%. Podemos observar que a classifica√ß√£o de falsos 0's se mostrou satisfat√≥ria. \n",
    "Por outro lado a classifica√ß√£o de falsos 1's ficou bem alta, isso ocorreu por conta de tweets que possuiam ironias,\n",
    "g√≠rias e dupla nega√ß√£o, o que √© caracter√≠stico no nicho de futebol e p√∫blico jovem. O classificador n√£o consegue identificar o sentimentos atribuidos √†s palavras apenas analisando as probabilidade Bayesianas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N√£o podemos utilizar o pr√≥prio classificador para alimentar nossa base de treinamento, pois o mesmo possuiria um vi√©s na classifica√ß√£o do novos tweets, visto que as frequ√™ncias de palavras relevantes e irrelevantes estariam baseadas no Data Frame de treinamento inicial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferentes cen√°rios em que Na√Øve Bayes pode ser aplicado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode-se utilizar o classificador Naive Bayes em interfaces de Email, por exemplo Gmail e Outlook, a classifica√ß√£o de quais emails estar√£o nas abas de destaque, outros ou spam s√£o classificadas a partir de Naive Bayes. Com isso os emails mais relevantes s√£o adionados nos destaques e os prov√°veis menos relevantes s√£o adicionados √† caixa de spam.\n",
    "\n",
    "Outro exemplo de aplica√ß√£o para Naive Bayes s√£o as tags de v√≠deos do YouTube.\n",
    "Quando um produtor de conte√∫do (YouTuber) posta seus v√≠deos, ele adiciona tags relacionadas ao conte√∫do referente ao v√≠deo. Dessa forma, quando o usu√°rio vai pesquisar por uma palavra relacionada √† essa tag, o v√≠deo √© recomendado como mais prov√°vel para o usu√°rio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sugest√µes de melhorias para a performace do Classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma poss√≠vel itera√ß√£o para o c√≥digo √© ter uma base de dados maior para Treinamento, al√©m de ter mais pessoas para realizarem a\n",
    "classifica√ß√£o desses tweets. Assim, a base de dados conter√° mais palavras e o vi√©s de escolha ser√° diminu√≠do, pois\n",
    "haver√° mais pessoas participando da classifica√ß√£o (diversidade de opini√£o).\n",
    "\n",
    "Outra itera√ß√£o para o c√≥digo √© criar uma fun√ß√£o que identifique palavras que foram escritas juntas e as separem.\n",
    "Dessa forma, as duas ou mais palavras ir√£o compor as tabela de frequencias de palavras relevantes e de palavras irrelevantes de maneira correta e assim a acur√°cida do nosso Classificador ser√° mais precisa.\n",
    "\n",
    "Material de apoio: https://towardsdatascience.com/?gi=e75d71ded956"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias Bibliogr√°ficas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)\n",
    "Acesso realizado no dia 10/09/2021\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/)\n",
    "Acesso realizado no dia 10/09/2021\n",
    "\n",
    "https://towardsdatascience.com/?gi=e75d71ded956\n",
    "Acesso realizado no dia 26/09/2021"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
